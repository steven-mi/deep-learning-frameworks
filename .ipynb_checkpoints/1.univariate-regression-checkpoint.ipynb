{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "Linear Regression is the **_Hello World_** of Machine Learning. In this notebook we will implement a _simple linear regression (univariate linear regression)_, a model with one predictor and one response variable. The goal is to recap and practice fundamental concepts of Machine Learning. After the exercise, you should have a deeper understanding of what a Machine Learning model is and how do you train such a model with a data set (supervised learning). To achieve this, you will:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Requirements\n",
    "### Knowledge\n",
    "You should have a basic knowledge of Machine Learning models, cost functions, optimization algorithms and also numpy and matplotlib. We will only recap these concepts for a better understanding and do not explain them in great detail. Suitable sources for acquiring this knowledge are:\n",
    "- [Simple Linear Regression Notebook](http://christianherta.de/lehre/dataScience/machineLearning/basics/univariate-linear-regression.php) by Christian Herta and his [lecture slides](http://christianherta.de/lehre/dataScience/machineLearning/linearRegression.pdf) (German)\n",
    "- Chapter 2 of the open classroom [Machine Learning](http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning) by Andrew Ng\n",
    "- Chapter 5.1 of [Deep Learning](http://www.deeplearningbook.org/contents/ml.html) by Ian Goodfellow \n",
    "- Some parts of chapter 1 and 3 of [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book) by Christopher M. Bishop\n",
    "- [numpy quickstart](https://docs.scipy.org/doc/numpy-1.15.1/user/quickstart.html)\n",
    "- [Matplotlib tutorials](https://matplotlib.org/tutorials/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python Modules\n",
    "\n",
    "By [deep.TEACHING](https://www.deep-teaching.org/) convention, all python modules needed to run the notebook are loaded centrally at the beginning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create a Dataset\n",
    "First of all, we generate a data set $\\Omega$ so you can evaluate your implementation. $\\Omega$ consists of tupels $(x^i,y^i)$. Let $x$ and $y$ be two numpy arrays of equal-length $m$. Create a linear function of $m$ data points in a given range $[x_{mi}, x_{max}]$. The $x$ values should be distributed equally over the defined interval. Add some Gaussian distributed noise to the corresponding $y$ values. Each response variable should differ from their ideal value by an additional $\\delta$.\n",
    "\n",
    "\\begin{equation}\n",
    "    f(x)= a + b * x + \\sigma , \\; with \\ X=\\left \\{  x \\in \\mathbb{R} \\mid x_{min} \\leqslant x \\leqslant  x_{max} \\right \\} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed random seed for testing\n",
    "np.random.seed(42)\n",
    "\n",
    "def linear_random_data(sample_size, a, b, x_min, x_max, noise_factor):\n",
    "    '''creates a randam data set based on a lienar function in a given interval\n",
    "\n",
    "    Args:\n",
    "        sample_size: number of data points\n",
    "        a: coefficent of x^0\n",
    "        b: coefficent of x^1\n",
    "        x_min: lower bound value range\n",
    "        x_max: upper bound value range\n",
    "        noise_factor: strength of nosie added to y \n",
    "\n",
    "    Returns:\n",
    "        x: array of x values | len(x)==len(y)\n",
    "        y: array of y values corresponding to x | len(x)==len(y)\n",
    "    '''\n",
    "    x = np.random.uniform(x_min, x_max, sample_size)\n",
    "    y = a + b * x + np.random.randn(len(x)) * noise_factor\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4255d01400>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = linear_random_data(10, 0., 5., -10, 10, 5)\n",
    "plt.plot(x,y, \"rx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Placeholder\n",
    "So far we have used numpy arrays to manage our data, but in order to build a model in tensorflow we need another structure, the placeholder. A placeholder is simply a variable that we will assign data to at a later date. It allows us to create our operations and build our computation graph, without needing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = tf.placeholder(dtype=tf.float32)\n",
    "Y_ = tf.placeholder(name=\"Y\", dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Univariate Linear Regression\n",
    "### Linear Hypothesis\n",
    "A short recap, a hypothesis $h_\\theta(x)$ is a certain function that we believe is similar to a target function that we like to model. A hypothesis $h_\\theta(x)$ is a function of $x$ with fixed parameters $\\theta$. The simplest kind of hypothesis is based on a linear equation with two parameters: \n",
    "\n",
    "\\begin{equation}\n",
    "    h_\\theta(x) = \\theta_{0} + \\theta_{1} * x \n",
    "\\end{equation}\n",
    "\n",
    "Implement hypothesis $h_\\theta(x)$ in the method `linear_hypothesis` and return it as a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_hypothesis(theta_0, theta_1):\n",
    "    ''' Combines given arguments in a linear equation and returns it as a function\n",
    "    \n",
    "    Args:\n",
    "        theta_0: first coefficient\n",
    "        theta_1: second coefficient\n",
    "        \n",
    "    Returns:\n",
    "        linear hypothesis as tensor and dependend on X_ (our placeholder for the input data)\n",
    "    ''' \n",
    "    return theta_1 * X_ + theta_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "A cost function $J$ depends on the given training data $D$ and hypothesis $h_\\theta(x)$. In the context of the simple linear regression, the cost function measures how wrong a model is regarding its ability to estimate the relationship between $x$ and $y$ for specific $\\theta$ values. Later we will treat this as an optimization problem and try to minimize the cost function $J_D(\\theta)$ to find optimal $\\theta$ values for our hypothesis $h_\\theta(x)$. The cost function we use in this exercise is the [Mean-Squared-Error](https://en.wikipedia.org/wiki/Mean_squared_error) cost function:\n",
    "\n",
    "\\begin{equation}\n",
    "    J_D(\\theta)=\\frac{1}{2m}\\sum_{i=1}^{m}{(h_\\theta(x_i)-y_i)^2}\n",
    "\\end{equation}\n",
    "\n",
    "Implement the cost function $J_D(\\theta)$ in the method `mse_cost_function`. The method should return a function that takes the values of $\\theta_0$ and $\\theta_1$ as an argument.\n",
    "\n",
    "Sidenote, the terms loss function or error function are often used interchangeably in the field of Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_cost_function(x, y, hypothesis):\n",
    "    ''' Implements MSE cost function as a function J(theta_0, theta_1) on given tranings data \n",
    "\n",
    "    Args:\n",
    "        x: vector of x values \n",
    "        y: vector of ground truth values y \n",
    "        hypothesis: a hypothesis tensor e.g. from linear_hypothesis\n",
    "    Returns:\n",
    "        lambda J(theta_0, theta_1) that models the cost function\n",
    "    '''\n",
    "    return tf.reduce_mean(tf.pow(hypothesis - Y_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Gradient Descent\n",
    "\n",
    "A short recap, the gradient descent algorithm is a first-order iterative optimization for finding a minimum of a function. From the current position in a (cost) function, the algorithm steps proportional to the negative of the gradient and repeats this until it reaches a local or global minimum and determines. Stepping proportional means that it does not go entirely in the direction of the negative gradient, but scaled by a fixed value $\\alpha$ also called the learning rate. Implementing the following formalized update rule is the core of the optimization process:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{j_{new}} \\leftarrow \\theta_{j_{old}} - \\alpha * \\frac{\\delta}{\\delta\\theta_{j_{old}}} J(\\theta_{old})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_theta(x, y, theta_0, theta_1, learning_rate, loss_function, sess):\n",
    "    ''' Updates learnable parameters theta_0 and theta_1\n",
    "\n",
    "    The update is done by calculating the partial derivities of\n",
    "    the cost function including the linear hypothesis. The\n",
    "    gradients scaled by a scalar are subtracted from the given\n",
    "    theta values.\n",
    "\n",
    "    Args:\n",
    "        x: array of x values\n",
    "        y: array of y values corresponding to x\n",
    "        theta_0: current theta_0 value\n",
    "        theta_1: current theta_1 value\n",
    "        learning_rate: value to scale the negative gradient\n",
    "\n",
    "    Returns:\n",
    "        t0: Updated theta_0\n",
    "        t1: Updated theta_1\n",
    "    '''\n",
    "    grad = tf.gradients(loss_function, [theta_0, theta_1])\n",
    "    t_grad = sess.run(grad, feed_dict={X_: x, Y_: y})\n",
    "    theta_0 = theta_0 - learning_rate * t_grad[0]\n",
    "    theta_1 = theta_1 - learning_rate * t_grad[1]\n",
    "    return theta_0, theta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `update_theta` method, we can now implement the gradient descent algorithm. Iterate over the update rule to find a $\\theta_0$ and a $\\theta_1$ that minimize our cost function $J_D(\\theta)$. This process is often called training of a machine learning model. During the training process create a history of all theta and cost values. We can use them later for evaluation. Implement a `verbose` argument that if true provides additional information during the process, e.g., final theta values after optimization or cost value at some iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, t0, t1, iterations=1000, learning_rate=0.0001):\n",
    "    ''' Minimize theta values of a linear model based on MSE cost function\n",
    "\n",
    "    Args:\n",
    "        x: vector, x values from the data set\n",
    "        y: vector, y values from the data set\n",
    "        iterations: scalar, number of theta updates\n",
    "        learning_rate: scalar, scales the negative gradient \n",
    "        verbose: boolean, print addition information \n",
    "\n",
    "    Returns:\n",
    "        t0: Updated theta_0\n",
    "        t1: Updated theta_1\n",
    "    '''\n",
    "    loss_history = []\n",
    "    # session\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    # gradient descent\n",
    "    for i in tqdm(range(iterations)):\n",
    "        # defining our forward path/loss function\n",
    "        mse = mse_cost_function(x, y, linear_hypothesis(t0, t1))\n",
    "        # one training step - updating theta\n",
    "        t0, t1 = update_theta(x, y, t0, t1, learning_rate, mse, sess)\n",
    "        # calculating loss and appending in to our list\n",
    "        loss = sess.run(mse, feed_dict={X_: x, Y_: y})\n",
    "        loss_history.append(loss)\n",
    "    return [t0, t1], loss_history, sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = tf.Variable(5, dtype=tf.float32)\n",
    "t1 = tf.Variable(-1, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "opt_thetas, loss_history, sess = gradient_descent(x, y, t0, t1, iterations=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model and Training Evaluation\n",
    "Now visualize the training process by plotting the `cost_hist` as a curve. Also, create a plot that shows the decision boundary of your final hypothesis (model) inside your data. Your plots should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_plt(loss_history, opt_thetas, x, y, sess):\n",
    "    ''' Plots a cost curve and the decision boundary\n",
    "\n",
    "    The Method plots a cost curve from a given training process (cost_hist). \n",
    "    It also plots the data set (x,y) and draws a linear decision boundary \n",
    "    with the parameters theta_0 and theta_1 into the plotted data set.\n",
    "\n",
    "    Args:\n",
    "        cost_hist: vector, history of all cost values from a opitmization\n",
    "        theta_0: scalar, model parameter for boundary\n",
    "        theta_1: scalar, model parameter for boundary\n",
    "        x: vector, x values from the data set\n",
    "        y: vector, y values from the data set\n",
    "    '''\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.plot(loss_history)\n",
    "    ax1.set_title('loss history')\n",
    "\n",
    "    t0, t1 = sess.run(opt_thetas)\n",
    "    ax2.plot(x, y, \"rx\")\n",
    "    ax2.plot(x, t0 + t1 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_plt(loss_history, opt_thetas, x, y, sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Licenses\n",
    "\n",
    "### Notebook License (CC-BY-SA 4.0)\n",
    "\n",
    "*The following license applies to the complete notebook, including code cells. It does however not apply to any referenced external media (e.g., images).*\n",
    "\n",
    "Exercise: Simple Linear Regression <br/>\n",
    "by Christian Herta, Benjamin Voigt <br/>\n",
    "is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).<br/>\n",
    "Based on a work at https://gitlab.com/deep.TEACHING.\n",
    "\n",
    "\n",
    "### Code License (MIT)\n",
    "\n",
    "*The following license only applies to code cells of the notebook.*\n",
    "\n",
    "Copyright 2018 Christian Herta, Benjamin Voigt\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
